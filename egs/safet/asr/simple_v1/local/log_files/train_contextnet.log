# Running on r8n03
# Started at Mon May 31 18:01:02 EDT 2021
# /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3 mmi_att_transformer_train.py 
Added key: store_based_barrier_key:1 to store for rank: 0
Loading lexicon and symbol tables
Loading L.fst
About to get train cuts
About to get train cuts
About to get Musan cuts
About to create train dataset
Using cut concatenation with duration factor 1.0 and gap 1.0.
Using SingleCutSampler.
About to create train dataloader
About to get dev cuts
About to get valid cuts
About to create dev dataset
About to create dev dataloader
Use pruned intersect for den_lats
About to create model
================================================================================
Model parameters summary:
================================================================================
* P_scores:                                                                27888
* blocks.0.convs.0.conv.depthwise.weight:                                    240
* blocks.0.convs.0.conv.depthwise.bias:                                       80
* blocks.0.convs.0.conv.pointwise.weight:                                  30720
* blocks.0.convs.0.conv.pointwise.bias:                                      384
* blocks.0.convs.0.norm.weight:                                              384
* blocks.0.convs.0.norm.bias:                                                384
* blocks.0.SE.conv.conv.depthwise.weight:                                   1152
* blocks.0.SE.conv.conv.depthwise.bias:                                      384
* blocks.0.SE.conv.conv.pointwise.weight:                                 147456
* blocks.0.SE.conv.conv.pointwise.bias:                                      384
* blocks.0.SE.conv.norm.weight:                                              384
* blocks.0.SE.conv.norm.bias:                                                384
* blocks.0.SE.bottleneck.0.weight:                                         18432
* blocks.0.SE.bottleneck.0.bias:                                              48
* blocks.0.SE.bottleneck.2.weight:                                         18432
* blocks.0.SE.bottleneck.2.bias:                                             384
* blocks.1.convs.0.conv.depthwise.weight:                                   1152
* blocks.1.convs.0.conv.depthwise.bias:                                      384
* blocks.1.convs.0.conv.pointwise.weight:                                 147456
* blocks.1.convs.0.conv.pointwise.bias:                                      384
* blocks.1.convs.0.norm.weight:                                              384
* blocks.1.convs.0.norm.bias:                                                384
* blocks.1.convs.1.conv.depthwise.weight:                                   1152
* blocks.1.convs.1.conv.depthwise.bias:                                      384
* blocks.1.convs.1.conv.pointwise.weight:                                 147456
* blocks.1.convs.1.conv.pointwise.bias:                                      384
* blocks.1.convs.1.norm.weight:                                              384
* blocks.1.convs.1.norm.bias:                                                384
* blocks.1.convs.2.conv.depthwise.weight:                                   1152
* blocks.1.convs.2.conv.depthwise.bias:                                      384
* blocks.1.convs.2.conv.pointwise.weight:                                 147456
* blocks.1.convs.2.conv.pointwise.bias:                                      384
* blocks.1.convs.2.norm.weight:                                              384
* blocks.1.convs.2.norm.bias:                                                384
* blocks.1.convs.3.conv.depthwise.weight:                                   1152
* blocks.1.convs.3.conv.depthwise.bias:                                      384
* blocks.1.convs.3.conv.pointwise.weight:                                 147456
* blocks.1.convs.3.conv.pointwise.bias:                                      384
* blocks.1.convs.3.norm.weight:                                              384
* blocks.1.convs.3.norm.bias:                                                384
* blocks.1.convs.4.conv.depthwise.weight:                                   1152
* blocks.1.convs.4.conv.depthwise.bias:                                      384
* blocks.1.convs.4.conv.pointwise.weight:                                 147456
* blocks.1.convs.4.conv.pointwise.bias:                                      384
* blocks.1.convs.4.norm.weight:                                              384
* blocks.1.convs.4.norm.bias:                                                384
* blocks.1.SE.conv.conv.depthwise.weight:                                   1152
* blocks.1.SE.conv.conv.depthwise.bias:                                      384
* blocks.1.SE.conv.conv.pointwise.weight:                                 147456
* blocks.1.SE.conv.conv.pointwise.bias:                                      384
* blocks.1.SE.conv.norm.weight:                                              384
* blocks.1.SE.conv.norm.bias:                                                384
* blocks.1.SE.bottleneck.0.weight:                                         18432
* blocks.1.SE.bottleneck.0.bias:                                              48
* blocks.1.SE.bottleneck.2.weight:                                         18432
* blocks.1.SE.bottleneck.2.bias:                                             384
* blocks.1.residual.conv.depthwise.weight:                                  1152
* blocks.1.residual.conv.depthwise.bias:                                     384
* blocks.1.residual.conv.pointwise.weight:                                147456
* blocks.1.residual.conv.pointwise.bias:                                     384
* blocks.1.residual.norm.weight:                                             384
* blocks.1.residual.norm.bias:                                               384
* blocks.2.convs.0.conv.depthwise.weight:                                   1152
* blocks.2.convs.0.conv.depthwise.bias:                                      384
* blocks.2.convs.0.conv.pointwise.weight:                                 294912
* blocks.2.convs.0.conv.pointwise.bias:                                      768
* blocks.2.convs.0.norm.weight:                                              768
* blocks.2.convs.0.norm.bias:                                                768
* blocks.2.convs.1.conv.depthwise.weight:                                   2304
* blocks.2.convs.1.conv.depthwise.bias:                                      768
* blocks.2.convs.1.conv.pointwise.weight:                                 589824
* blocks.2.convs.1.conv.pointwise.bias:                                      768
* blocks.2.convs.1.norm.weight:                                              768
* blocks.2.convs.1.norm.bias:                                                768
* blocks.2.convs.2.conv.depthwise.weight:                                   2304
* blocks.2.convs.2.conv.depthwise.bias:                                      768
* blocks.2.convs.2.conv.pointwise.weight:                                 589824
* blocks.2.convs.2.conv.pointwise.bias:                                      768
* blocks.2.convs.2.norm.weight:                                              768
* blocks.2.convs.2.norm.bias:                                                768
* blocks.2.convs.3.conv.depthwise.weight:                                   2304
* blocks.2.convs.3.conv.depthwise.bias:                                      768
* blocks.2.convs.3.conv.pointwise.weight:                                 589824
* blocks.2.convs.3.conv.pointwise.bias:                                      768
* blocks.2.convs.3.norm.weight:                                              768
* blocks.2.convs.3.norm.bias:                                                768
* blocks.2.convs.4.conv.depthwise.weight:                                   2304
* blocks.2.convs.4.conv.depthwise.bias:                                      768
* blocks.2.convs.4.conv.pointwise.weight:                                 589824
* blocks.2.convs.4.conv.pointwise.bias:                                      768
* blocks.2.convs.4.norm.weight:                                              768
* blocks.2.convs.4.norm.bias:                                                768
* blocks.2.SE.conv.conv.depthwise.weight:                                   2304
* blocks.2.SE.conv.conv.depthwise.bias:                                      768
* blocks.2.SE.conv.conv.pointwise.weight:                                 589824
* blocks.2.SE.conv.conv.pointwise.bias:                                      768
* blocks.2.SE.conv.norm.weight:                                              768
* blocks.2.SE.conv.norm.bias:                                                768
* blocks.2.SE.bottleneck.0.weight:                                         73728
* blocks.2.SE.bottleneck.0.bias:                                              96
* blocks.2.SE.bottleneck.2.weight:                                         73728
* blocks.2.SE.bottleneck.2.bias:                                             768
* blocks.2.residual.conv.depthwise.weight:                                  1152
* blocks.2.residual.conv.depthwise.bias:                                     384
* blocks.2.residual.conv.pointwise.weight:                                294912
* blocks.2.residual.conv.pointwise.bias:                                     768
* blocks.2.residual.norm.weight:                                             768
* blocks.2.residual.norm.bias:                                               768
* blocks.3.convs.0.conv.depthwise.weight:                                   2304
* blocks.3.convs.0.conv.depthwise.bias:                                      768
* blocks.3.convs.0.conv.pointwise.weight:                                 589824
* blocks.3.convs.0.conv.pointwise.bias:                                      768
* blocks.3.convs.0.norm.weight:                                              768
* blocks.3.convs.0.norm.bias:                                                768
* blocks.3.convs.1.conv.depthwise.weight:                                   2304
* blocks.3.convs.1.conv.depthwise.bias:                                      768
* blocks.3.convs.1.conv.pointwise.weight:                                 589824
* blocks.3.convs.1.conv.pointwise.bias:                                      768
* blocks.3.convs.1.norm.weight:                                              768
* blocks.3.convs.1.norm.bias:                                                768
* blocks.3.convs.2.conv.depthwise.weight:                                   2304
* blocks.3.convs.2.conv.depthwise.bias:                                      768
* blocks.3.convs.2.conv.pointwise.weight:                                 589824
* blocks.3.convs.2.conv.pointwise.bias:                                      768
* blocks.3.convs.2.norm.weight:                                              768
* blocks.3.convs.2.norm.bias:                                                768
* blocks.3.convs.3.conv.depthwise.weight:                                   2304
* blocks.3.convs.3.conv.depthwise.bias:                                      768
* blocks.3.convs.3.conv.pointwise.weight:                                 589824
* blocks.3.convs.3.conv.pointwise.bias:                                      768
* blocks.3.convs.3.norm.weight:                                              768
* blocks.3.convs.3.norm.bias:                                                768
* blocks.3.convs.4.conv.depthwise.weight:                                   2304
* blocks.3.convs.4.conv.depthwise.bias:                                      768
* blocks.3.convs.4.conv.pointwise.weight:                                 589824
* blocks.3.convs.4.conv.pointwise.bias:                                      768
* blocks.3.convs.4.norm.weight:                                              768
* blocks.3.convs.4.norm.bias:                                                768
* blocks.3.SE.conv.conv.depthwise.weight:                                   2304
* blocks.3.SE.conv.conv.depthwise.bias:                                      768
* blocks.3.SE.conv.conv.pointwise.weight:                                 589824
* blocks.3.SE.conv.conv.pointwise.bias:                                      768
* blocks.3.SE.conv.norm.weight:                                              768
* blocks.3.SE.conv.norm.bias:                                                768
* blocks.3.SE.bottleneck.0.weight:                                         73728
* blocks.3.SE.bottleneck.0.bias:                                              96
* blocks.3.SE.bottleneck.2.weight:                                         73728
* blocks.3.SE.bottleneck.2.bias:                                             768
* blocks.3.residual.conv.depthwise.weight:                                  2304
* blocks.3.residual.conv.depthwise.bias:                                     768
* blocks.3.residual.conv.pointwise.weight:                                589824
* blocks.3.residual.conv.pointwise.bias:                                     768
* blocks.3.residual.norm.weight:                                             768
* blocks.3.residual.norm.bias:                                               768
* blocks.4.convs.0.conv.depthwise.weight:                                   2304
* blocks.4.convs.0.conv.depthwise.bias:                                      768
* blocks.4.convs.0.conv.pointwise.weight:                                 589824
* blocks.4.convs.0.conv.pointwise.bias:                                      768
* blocks.4.convs.0.norm.weight:                                              768
* blocks.4.convs.0.norm.bias:                                                768
* blocks.4.convs.1.conv.depthwise.weight:                                   2304
* blocks.4.convs.1.conv.depthwise.bias:                                      768
* blocks.4.convs.1.conv.pointwise.weight:                                 589824
* blocks.4.convs.1.conv.pointwise.bias:                                      768
* blocks.4.convs.1.norm.weight:                                              768
* blocks.4.convs.1.norm.bias:                                                768
* blocks.4.convs.2.conv.depthwise.weight:                                   2304
* blocks.4.convs.2.conv.depthwise.bias:                                      768
* blocks.4.convs.2.conv.pointwise.weight:                                 589824
* blocks.4.convs.2.conv.pointwise.bias:                                      768
* blocks.4.convs.2.norm.weight:                                              768
* blocks.4.convs.2.norm.bias:                                                768
* blocks.4.convs.3.conv.depthwise.weight:                                   2304
* blocks.4.convs.3.conv.depthwise.bias:                                      768
* blocks.4.convs.3.conv.pointwise.weight:                                 589824
* blocks.4.convs.3.conv.pointwise.bias:                                      768
* blocks.4.convs.3.norm.weight:                                              768
* blocks.4.convs.3.norm.bias:                                                768
* blocks.4.convs.4.conv.depthwise.weight:                                   2304
* blocks.4.convs.4.conv.depthwise.bias:                                      768
* blocks.4.convs.4.conv.pointwise.weight:                                 589824
* blocks.4.convs.4.conv.pointwise.bias:                                      768
* blocks.4.convs.4.norm.weight:                                              768
* blocks.4.convs.4.norm.bias:                                                768
* blocks.4.SE.conv.conv.depthwise.weight:                                   2304
* blocks.4.SE.conv.conv.depthwise.bias:                                      768
* blocks.4.SE.conv.conv.pointwise.weight:                                 589824
* blocks.4.SE.conv.conv.pointwise.bias:                                      768
* blocks.4.SE.conv.norm.weight:                                              768
* blocks.4.SE.conv.norm.bias:                                                768
* blocks.4.SE.bottleneck.0.weight:                                         73728
* blocks.4.SE.bottleneck.0.bias:                                              96
* blocks.4.SE.bottleneck.2.weight:                                         73728
* blocks.4.SE.bottleneck.2.bias:                                             768
* blocks.4.residual.conv.depthwise.weight:                                  2304
* blocks.4.residual.conv.depthwise.bias:                                     768
* blocks.4.residual.conv.pointwise.weight:                                589824
* blocks.4.residual.conv.pointwise.bias:                                     768
* blocks.4.residual.norm.weight:                                             768
* blocks.4.residual.norm.bias:                                               768
* blocks.5.convs.0.conv.depthwise.weight:                                   2304
* blocks.5.convs.0.conv.depthwise.bias:                                      768
* blocks.5.convs.0.conv.pointwise.weight:                                 737280
* blocks.5.convs.0.conv.pointwise.bias:                                      960
* blocks.5.convs.0.norm.weight:                                              960
* blocks.5.convs.0.norm.bias:                                                960
* blocks.5.SE.conv.conv.depthwise.weight:                                   2880
* blocks.5.SE.conv.conv.depthwise.bias:                                      960
* blocks.5.SE.conv.conv.pointwise.weight:                                 921600
* blocks.5.SE.conv.conv.pointwise.bias:                                      960
* blocks.5.SE.conv.norm.weight:                                              960
* blocks.5.SE.conv.norm.bias:                                                960
* blocks.5.SE.bottleneck.0.weight:                                        115200
* blocks.5.SE.bottleneck.0.bias:                                             120
* blocks.5.SE.bottleneck.2.weight:                                        115200
* blocks.5.SE.bottleneck.2.bias:                                             960
* output_layer.weight:                                                    160320
* output_layer.bias:                                                         167
================================================================================
Total: 15750607
================================================================================
No ali_model
epoch 0, learning rate 0
batch 0, epoch 0/10 global average objf: 1.640062 over 1094.0 frames (100.0% kept), current batch average objf: 1.640060 over 1094 frames (100.0% kept) avg time waiting for batch 8.165s
Reducer buckets have been rebuilt in this iteration.
batch 10, epoch 0/10 global average objf: 1.655442 over 12430.0 frames (100.0% kept), current batch average objf: 1.771263 over 1201 frames (100.0% kept) avg time waiting for batch 0.819s
batch 20, epoch 0/10 global average objf: 1.679502 over 24095.0 frames (100.0% kept), current batch average objf: 1.556799 over 1126 frames (100.0% kept) avg time waiting for batch 0.410s
batch 30, epoch 0/10 global average objf: 1.747970 over 35610.0 frames (100.0% kept), current batch average objf: 1.840732 over 1097 frames (100.0% kept) avg time waiting for batch 0.274s
batch 40, epoch 0/10 global average objf: 1.752210 over 47358.0 frames (100.0% kept), current batch average objf: 1.507041 over 1216 frames (100.0% kept) avg time waiting for batch 0.206s
batch 50, epoch 0/10 global average objf: 1.756460 over 59224.0 frames (100.0% kept), current batch average objf: 1.557976 over 1209 frames (100.0% kept) avg time waiting for batch 0.165s
batch 60, epoch 0/10 global average objf: 1.754845 over 71106.0 frames (100.0% kept), current batch average objf: 1.759909 over 1212 frames (100.0% kept) avg time waiting for batch 0.138s
batch 70, epoch 0/10 global average objf: 1.759631 over 82813.0 frames (100.0% kept), current batch average objf: 1.765268 over 1228 frames (100.0% kept) avg time waiting for batch 0.119s
batch 80, epoch 0/10 global average objf: 1.755651 over 94661.0 frames (100.0% kept), current batch average objf: 2.084969 over 1191 frames (100.0% kept) avg time waiting for batch 0.104s
batch 90, epoch 0/10 global average objf: 1.754661 over 106319.0 frames (100.0% kept), current batch average objf: 1.770571 over 1194 frames (100.0% kept) avg time waiting for batch 0.093s
batch 100, epoch 0/10 global average objf: 1.755986 over 118162.0 frames (100.0% kept), current batch average objf: 1.730187 over 1197 frames (100.0% kept) avg time waiting for batch 0.084s
batch 110, epoch 0/10 global average objf: 1.752569 over 129930.0 frames (100.0% kept), current batch average objf: 1.918371 over 1135 frames (100.0% kept) avg time waiting for batch 0.076s
batch 120, epoch 0/10 global average objf: 1.738400 over 141387.0 frames (100.0% kept), current batch average objf: 1.080515 over 1143 frames (100.0% kept) avg time waiting for batch 0.070s
batch 130, epoch 0/10 global average objf: 1.736673 over 153085.0 frames (100.0% kept), current batch average objf: 1.431201 over 1148 frames (100.0% kept) avg time waiting for batch 0.065s
batch 140, epoch 0/10 global average objf: 1.727503 over 165097.0 frames (100.0% kept), current batch average objf: 1.947043 over 1164 frames (100.0% kept) avg time waiting for batch 0.060s
batch 150, epoch 0/10 global average objf: 1.719253 over 177042.0 frames (100.0% kept), current batch average objf: 1.726376 over 1174 frames (98.5% kept) avg time waiting for batch 0.056s
batch 160, epoch 0/10 global average objf: 1.714376 over 188805.0 frames (100.0% kept), current batch average objf: 1.801035 over 1189 frames (100.0% kept) avg time waiting for batch 0.053s
batch 170, epoch 0/10 global average objf: 1.712438 over 200714.0 frames (100.0% kept), current batch average objf: 1.445937 over 1191 frames (100.0% kept) avg time waiting for batch 0.050s
my line number is 318
1
TimeConstraint(max_duration=50.0, max_samples=None, max_frames=None, current=318.6248125)
/home/hltcoe/aarora/lhotse/lhotse/dataset/sampling.py:316: UserWarning: The first cut drawn in batch collection violates the max_frames or max_cuts constraints - we'll return it anyway. Consider increasing max_frames/max_cuts.
  warnings.warn("The first cut drawn in batch collection violates the max_frames or max_cuts "
Traceback (most recent call last):
  File "mmi_att_transformer_train.py", line 691, in <module>
    main()
  File "mmi_att_transformer_train.py", line 684, in main
    mp.spawn(run, args=(world_size, args), nprocs=world_size, join=True)
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/home/hltcoe/aarora/snowfall/egs/safet/asr/simple_v1/mmi_att_transformer_train.py", line 600, in run
    objf, valid_objf, global_batch_idx_train = train_one_epoch(
  File "/home/hltcoe/aarora/snowfall/egs/safet/asr/simple_v1/mmi_att_transformer_train.py", line 251, in train_one_epoch
    curr_batch_objf, curr_batch_frames, curr_batch_all_frames = get_objf(
  File "/home/hltcoe/aarora/snowfall/egs/safet/asr/simple_v1/mmi_att_transformer_train.py", line 107, in get_objf
    mmi_loss, tot_frames, all_frames = loss_fn(nnet_output, texts, supervision_segments)
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/nn/modules/module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/hltcoe/aarora/snowfall/snowfall/objectives/mmi.py", line 222, in forward
    return func(nnet_output=nnet_output,
  File "/home/hltcoe/aarora/snowfall/snowfall/objectives/mmi.py", line 184, in _compute_mmi_loss_pruned
    den_tot_scores = den_lats.get_tot_scores(log_semiring=True,
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/k2/fsa.py", line 606, in get_tot_scores
    tot_scores = k2.autograd._GetTotScoresFunction.apply(
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/k2/autograd.py", line 49, in forward
    tot_scores = fsas._get_tot_scores(use_double_scores=use_double_scores,
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/k2/fsa.py", line 585, in _get_tot_scores
    forward_scores = self._get_forward_scores(use_double_scores,
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/k2/fsa.py", line 535, in _get_forward_scores
    entering_arc_batches=self._get_entering_arc_batches(),
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/k2/fsa.py", line 475, in _get_entering_arc_batches
    incoming_arcs=self._get_incoming_arcs(),
  File "/home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/k2/fsa.py", line 461, in _get_incoming_arcs
    cache[name] = _k2.get_incoming_arcs(self.arcs,
RuntimeError: CUDA out of memory. Tried to allocate 17179869182.39 GiB (GPU 0; 31.75 GiB total capacity; 18.34 GiB already allocated; 11.62 GiB free; 18.91 GiB reserved in total by PyTorch)
Exception raised from malloc at /opt/conda/conda-bld/pytorch_1616554788289/work/c10/cuda/CUDACachingAllocator.cpp:288 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x2aab198312f2 in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1bc21 (0x2aab195cdc21 in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1c944 (0x2aab195ce944 in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1cf63 (0x2aab195cef63 in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #4: k2::PytorchCudaContext::Allocate(unsigned long, void**) + 0x33 (0x2aab34d4b583 in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/libk2context.so)
frame #5: k2::NewRegion(std::shared_ptr<k2::Context>, unsigned long) + 0x11e (0x2aab34a97ffe in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/libk2context.so)
frame #6: <unknown function> + 0x24b4ad (0x2aab34c174ad in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/libk2context.so)
frame #7: k2::GetTransposeReordering(k2::Ragged<int>&, int) + 0x2ff (0x2aab34c3508f in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/libk2context.so)
frame #8: k2::GetIncomingArcs(k2::Ragged<k2::Arc>&, k2::Array1<int> const&) + 0x11a (0x2aab34b1872a in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/libk2context.so)
frame #9: <unknown function> + 0x39384 (0x2aab33dd8384 in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/_k2.cpython-38-x86_64-linux-gnu.so)
frame #10: <unknown function> + 0x1b8ff (0x2aab33dba8ff in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/_k2.cpython-38-x86_64-linux-gnu.so)
frame #11: PyCFunction_Call + 0x58 (0x5555556a8348 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #12: _PyObject_MakeTpCall + 0x23c (0x555555697dbc in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #13: _PyEval_EvalFrameDefault + 0x4596 (0x555555723666 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #14: <unknown function> + 0x19a36b (0x5555556ee36b in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #15: <unknown function> + 0x103a61 (0x555555657a61 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #16: <unknown function> + 0x19a36b (0x5555556ee36b in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #17: <unknown function> + 0x103a61 (0x555555657a61 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #18: <unknown function> + 0x19a36b (0x5555556ee36b in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #19: <unknown function> + 0x103a61 (0x555555657a61 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #20: _PyEval_EvalCodeWithName + 0x300 (0x5555556ed270 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #21: <unknown function> + 0x19a480 (0x5555556ee480 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #22: <unknown function> + 0x10343c (0x55555565743c in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #23: _PyFunction_Vectorcall + 0x10b (0x5555556edfcb in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #24: PyObject_CallObject + 0x52 (0x5555556f3a22 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #25: THPFunction_apply(_object*, _object*) + 0x8fd (0x2aaacc6f83fd in /home/hltcoe/aarora/miniconda3/envs/k2/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #26: PyCFunction_Call + 0xe0 (0x5555556a83d0 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #27: _PyObject_MakeTpCall + 0x23c (0x555555697dbc in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #28: _PyEval_EvalFrameDefault + 0x4596 (0x555555723666 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #29: _PyEval_EvalCodeWithName + 0x300 (0x5555556ed270 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #30: <unknown function> + 0x19a480 (0x5555556ee480 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #31: <unknown function> + 0x10343c (0x55555565743c in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #32: _PyEval_EvalCodeWithName + 0x300 (0x5555556ed270 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #33: _PyFunction_Vectorcall + 0x1e3 (0x5555556ee0a3 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #34: <unknown function> + 0x10343c (0x55555565743c in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #35: _PyFunction_Vectorcall + 0x10b (0x5555556edfcb in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #36: <unknown function> + 0x19a5d9 (0x5555556ee5d9 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #37: PyObject_Call + 0x414 (0x555555698754 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #38: _PyEval_EvalFrameDefault + 0x1fe6 (0x5555557210b6 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #39: _PyEval_EvalCodeWithName + 0x300 (0x5555556ed270 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #40: _PyObject_Call_Prepend + 0x181 (0x5555556eeb61 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #41: <unknown function> + 0x19af0a (0x5555556eef0a in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #42: _PyObject_MakeTpCall + 0x23c (0x555555697dbc in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #43: _PyEval_EvalFrameDefault + 0x475 (0x55555571f545 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #44: _PyEval_EvalCodeWithName + 0x8b1 (0x5555556ed821 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #45: _PyFunction_Vectorcall + 0x1e3 (0x5555556ee0a3 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #46: <unknown function> + 0x10343c (0x55555565743c in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #47: _PyEval_EvalCodeWithName + 0x300 (0x5555556ed270 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #48: _PyFunction_Vectorcall + 0x1e3 (0x5555556ee0a3 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #49: <unknown function> + 0x10343c (0x55555565743c in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #50: _PyFunction_Vectorcall + 0x10b (0x5555556edfcb in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #51: PyObject_Call + 0x414 (0x555555698754 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #52: _PyEval_EvalFrameDefault + 0x1fe6 (0x5555557210b6 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #53: _PyFunction_Vectorcall + 0x10b (0x5555556edfcb in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #54: PyObject_Call + 0x414 (0x555555698754 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #55: _PyEval_EvalFrameDefault + 0x1fe6 (0x5555557210b6 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #56: _PyFunction_Vectorcall + 0x10b (0x5555556edfcb in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #57: <unknown function> + 0x103a40 (0x555555657a40 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #58: _PyEval_EvalCodeWithName + 0x300 (0x5555556ed270 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #59: _PyFunction_Vectorcall + 0x1e3 (0x5555556ee0a3 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #60: <unknown function> + 0x103a40 (0x555555657a40 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #61: _PyFunction_Vectorcall + 0x10b (0x5555556edfcb in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #62: <unknown function> + 0x1035db (0x5555556575db in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)
frame #63: _PyEval_EvalCodeWithName + 0x300 (0x5555556ed270 in /home/hltcoe/aarora/miniconda3/envs/k2/bin/python3)


# Accounting: time=68 threads=1
# Finished at Mon May 31 18:02:10 EDT 2021 with status 1
